<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: devops | /* steve jansen */]]></title>
  <link href="http://steve-jansen.github.io/blog/categories/devops/atom.xml" rel="self"/>
  <link href="http://steve-jansen.github.io/"/>
  <updated>2014-12-03T11:34:14-05:00</updated>
  <id>http://steve-jansen.github.io/</id>
  <author>
    <name><![CDATA[Steve Jansen]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Integrating Rackspace Auto Scale Groups with ObjectRocket Mongo databases]]></title>
    <link href="http://steve-jansen.github.io/blog/2014/12/01/integrating-rackspace-auto-scale-groups-with-objectrocket-mongo-databases/"/>
    <updated>2014-12-01T13:00:58-05:00</updated>
    <id>http://steve-jansen.github.io/blog/2014/12/01/integrating-rackspace-auto-scale-groups-with-objectrocket-mongo-databases</id>
    <content type="html"><![CDATA[<p>Thanks to some pretty awesome support from Jon Fanti and John Moore at <a href="http://objectrocket.com">ObjectRocket</a>,
I learned this week that we had missed two key optimizations for using ObjectRocket MongoDBs with Rackspace
Auto Scaling groups (ASGs).</p>

<h2>ServiceNet</h2>

<p>First, ObjectRocket support can provide medium and large customers with a server FQDN that resolves to a
<a href="http://www.rackspace.com/knowledge_center/frequently-asked-question/what-is-servicenet">ServiceNet</a> private IP.
You can use this FQDN instead of the server name shown in the connect string for your instance.  As long
as your cloud servers and ObjectRocket are in the same Rackspace data center, the ServiceNet connection string
will avoid data transfer charges and keep your packets from transiting the public Internet.</p>

<h2>Dynamic IP ACLs</h2>

<p>We struggled to manually maintain the list of authorized IPs for our ObjectRocket MongoDB instances
when a ASG would add a new node.  We had a backlog plan to script the IP ACLs using Chef, but, hadn&rsquo;t
found the time yet.</p>

<p>Fortunately, ObjectRocket already supports this!  See <a href="https://app.objectrocket.com/external/rackspace">https://app.objectrocket.com/external/rackspace</a></p>

<p><img src="/images/2014-12-01.png" alt="Screenshot of ObjectRocket integration with Rackspace" /></p>

<p>According to John, the ObjectRocket integration with your Rackspace Cloud account will automatically sync
the IP ACLs with your list of current Cloud VMs.  Moreover, the integration will ignore any manual IP ACLs
you create (as long as your description doesn&rsquo;t use the <code>rax-</code> prefix).</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[How to use Jenkins to monitor cron jobs]]></title>
    <link href="http://steve-jansen.github.io/blog/2014/11/20/how-to-use-jenkins-to-monitor-cron-jobs/"/>
    <updated>2014-11-20T17:46:46-05:00</updated>
    <id>http://steve-jansen.github.io/blog/2014/11/20/how-to-use-jenkins-to-monitor-cron-jobs</id>
    <content type="html"><![CDATA[<p>Cron jobs have a funny way of being ignored.  Either no one knows the job is failing because the job
doesn&rsquo;t tell anyone.   Or, the job is spamming your e-mail inbox many times a day, regardless of success
or failure, which means you just ignore the e-mails.</p>

<p>I&rsquo;ve seen the &ldquo;Monitor an external job&rdquo; option for new Jenkins jobs before, and never paid much attention.
Turns out it&rsquo;s a great bucket for storing logs and results of cron jobs.</p>

<p>The <a href="https://wiki.jenkins-ci.org/display/JENKINS/Monitoring+external+jobs">external-monitor-job</a> plugin
seems to ship with the Jenkins war file.  So, your Jenkins should have it out of the box.</p>

<p>Creating a job is pretty simple.  It&rsquo;s just a name and description.  Click &ldquo;New Item&rdquo; in Jenkins and
select the &ldquo;Monitor an external job&rdquo; option.  This creates a job of type <code>hudson.model.ExternalJob</code>.</p>

<p>The <a href="https://wiki.jenkins-ci.org/display/JENKINS/Monitoring+external+jobs">wiki</a> describes a
fairly complicated method to download the Jenkins jar files onto the server running
your cron jobs, and then use the Java runtime to run a jar with your cron script as an
argument.  The jar presumably forks your a new shell to run your desired cron command and
sends the output/result to Jenkins.</p>

<p>There&rsquo;s a much easier way to do this.  Redirect or <code>tee</code> your job&rsquo;s stdout/stderr output to a
temp file.  Then post the result code and log file via <code>curl</code> to Jenkins.  No need to
download jar files.  No need to even have Java runtime on the server.</p>

<p>Just POST a small XML document with the log contents (binary encoded) and the
exit code to Jenkins @ <code>/job/:jobName/postBuildResult</code> where <code>:jobName</code> is the
URL encoded name of your monitoring job in Jenkins.</p>

<p>``` bash [example cron script]</p>

<h1>!/bin/sh</h1>

<h1>example cron script to post logs to Jenkins</h1>

<h1>exit on error</h1>

<p>set -e</p>

<p>log=<code>mktemp -t tmp</code>
timer=<code>date +"%s"</code>
jenkins_job=my_monitoring_job
jenkins_server=<a href="http://jenkins.example.com:8080/jenkins/job/$jenkins_job/postBuildResult">http://jenkins.example.com:8080/jenkins/job/$jenkins_job/postBuildResult</a></p>

<h1>see <a href="http://jenkins.example.com:8080/me/configure">http://jenkins.example.com:8080/me/configure</a> to get your username and API token</h1>

<p>jenkins_username=myusername
jenkins_token=abcdef0123456789fedcba9876543210</p>

<p>function banner() {
  echo $(printf &lsquo;#%.0s&rsquo; {1..80}) >> &ldquo;$log&rdquo;
}</p>

<p>function report() {
  result=$?
  timer=$((<code>date +"%s"</code> &ndash; $timer))</p>

<p>  banner
  echo &ldquo;<code>whoami</code>@<code>hostname -f</code> <code>date</code>: elapsed $timer second(s)&rdquo; >> &ldquo;$log&rdquo;
  echo &ldquo;exit code $result&rdquo; >> &ldquo;$log&rdquo;</p>

<p>  # binary encode the log file for Jenkins
  msg=<code>cat "$log" | hexdump -v -e '1/1 "%02x"'</code></p>

<p>  # post the log to jenkins
  echo curl -X POST \</p>

<pre><code>   -u "$jenkins_username:$jenkins_token" \
   -d "&lt;run&gt;&lt;log encoding=\"hexBinary\"&gt;$msg&lt;/log&gt;&lt;result&gt;$result&lt;/result&gt;&lt;duration&gt;$timer&lt;/duration&gt;&lt;/run&gt;" \
    $jenkins_server/job/$jenkins_job/postBuildResult
</code></pre>

<p>}</p>

<p>trap report EXIT;</p>

<p>banner
echo &ldquo;hello, world @ <code>date</code>!&rdquo; | tee &ldquo;$log&rdquo;
```</p>

<p><code>bash [sample `crontab -e` entry]
MAILTO=""
0 * * * * /bin/sh /your/directory/myjob.sh
</code></p>

<p>A sample of the build log on Jenkins with a green/red build status:</p>

<p><img src="images/2014-11-20.png" alt="Sample Jenkins Build Log" /></p>

<p>Credit to <a href="http://stackoverflow.com/a/25611940/1995977">Taytay on Stackoverflow.com</a>
for figuring out how to use <code>hexdump</code> to properly encode the XML for Jenkins.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Finding Chef nodes bootstrapped in the last X hours]]></title>
    <link href="http://steve-jansen.github.io/blog/2014/10/17/finding-chef-nodes-bootstrapped-in-the-last-x-hours/"/>
    <updated>2014-10-17T18:47:44-04:00</updated>
    <id>http://steve-jansen.github.io/blog/2014/10/17/finding-chef-nodes-bootstrapped-in-the-last-x-hours</id>
    <content type="html"><![CDATA[<p>I needed to write a script to garbage collect old nodes in Chef related to
auto-scaling groups.</p>

<p>I decided to search for nodes bootstrapped in the last X hours.</p>

<p>I experimented with ways to find nodes that have been up for less than X hours.
In this example, I search for nodes that have been up for 8 hours or less.
Of course, this assumes you never restart your nodes:</p>

<p><code>
knife exec -E 'search(:node, "uptime_seconds:[0 TO #{ 8 * 60 * 60 }]") { |n| puts n.name }'
</code>
I also tried finding nodes that converged in the last 8 hours (which would have
to be combined with some other filter of course):</p>

<p><code>
knife exec -E 'b = Time.now.to_i; a = (b - (8*60*60)).to_i; search(:node, "ohai_time:[#{a} TO #{b}]") { |n| puts n.name }'
</code></p>

<p>Overall, I think the easiest option is to just set a node attribute like
&lsquo;bootstrap_date&rsquo; at bootstrap (or set it if it&rsquo;s nil).  This would be a clearcut
way to find out how old a node truly is.</p>

<p>One of my colleagues pointed out that <a href="https://github.com/opscode/chef-metal">Chef Metal</a>
sets a very handy <code>node['metal']['location']['allocated_at']</code> attribute that gets
the job done if you are spinning up new nodes with metal.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[regexes for the serverspec 2 update]]></title>
    <link href="http://steve-jansen.github.io/blog/2014/10/03/regexes-for-the-serverspec-2-update/"/>
    <updated>2014-10-03T18:24:25-04:00</updated>
    <id>http://steve-jansen.github.io/blog/2014/10/03/regexes-for-the-serverspec-2-update</id>
    <content type="html"><![CDATA[<p>The Serverspec team just released v2 of their outstanding testing library
today, after a very long beta period.  The v2 release had a
<a href="http://serverspec.org/changes-of-v2.html">few breaking breaking changes</a>
due to dropped rspec matchers that had been deprecated.</p>

<p>If your <a href="http://kitchen.ci/">test-kitchen</a> tests recently broke today,
here&rsquo;s a few regexes I used with Sublime Text&rsquo;s regex find/replace
to rewrite the dropped matchers for the new matchers.</p>

<p>```
it\s<em>{\s</em>(should|should_not)\s<em>return_(stdout|stderr)\s</em>(?(\/.<em>\/))?\s</em>}
its(:\2) { \1 match \3 }</p>

<p>it\s<em>{\s</em>(should|should_not)\s<em>return_(stdout|stderr)\s</em>(?(\&ldquo;.<em>\&rdquo;))?\s</em>}
its(:\2) { \1 contain \3 }</p>

<p>it\s<em>{\s</em>(should|should_not)\s<em>return_(stdout|stderr)\s</em>(?(&lsquo;.<em>&rsquo;))?\s</em>}
its(:\2) { \1 contain \3 }</p>

<p>it\s<em>{\s</em>(should|should_not)\s<em>return_exit_status\s</em>(\d+)\s*}
its(:exit_status) { \1 eq \2 }
```</p>

<p>Hopefully the kitchen busser project will one day add support for
Gemfile-style constraints on the test node, since busser always
<a href="https://github.com/test-kitchen/test-kitchen/issues/242#issuecomment-28991870">installs the latest version of a busser plugin gem today.</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Chef'ing custom nginx configs with the nginx cookbook]]></title>
    <link href="http://steve-jansen.github.io/blog/2014/08/27/chefing-custom-nginx-configs-with-the-nginx-cookbook/"/>
    <updated>2014-08-27T19:41:10-04:00</updated>
    <id>http://steve-jansen.github.io/blog/2014/08/27/chefing-custom-nginx-configs-with-the-nginx-cookbook</id>
    <content type="html"><![CDATA[<p>The <a href="http://supermarket.getchef.com/cookbooks/nginx">nginx</a> cookbook has been
super helpful Chef'ing some web apps recently.  One thing I struggled to
understand was how to use my own custom conf, like <code>/etc/nginx/nginx.conf</code>, that
is optimized for how I use nginx.</p>

<p>One solution I tried, which is probably a Chef anti-pattern, is to only include
the nginx cookbook on the initial converge:</p>

<h2>The Wrong Way</h2>

<p>``` ruby</p>

<h1>the nginx community cookbook will relentlessly revert conf files,</h1>

<h1>so avoid running it unless nginx isn&rsquo;t installed,</h1>

<h1>or we explicitly reset/delete the node attribute</h1>

<p>include_recipe &lsquo;nginx&rsquo; unless node[&lsquo;nginx&rsquo;][&lsquo;installed&rsquo;]
node.set[&lsquo;nginx&rsquo;][&lsquo;installed&rsquo;] = true</p>

<h1>our custom nginx.conf</h1>

<p>template &lsquo;/etc/nginx/nginx.conf&rsquo; do
   source &lsquo;nginx.conf.erb&rsquo;
   owner &lsquo;root&rsquo;
   group &lsquo;root&rsquo;
   mode  &lsquo;0644&rsquo;
   notifies :reload, &ldquo;service[nginx]&rdquo;, :delayed
end
```</p>

<p>I knew this was wrong when I wrote it.   Chef is all about idempotency.
But, I couldn&rsquo;t figure out a way to keep the nginx cookbook from reverting my
custom conf during subsequent converges, only to have my <code>template</code> restore my
custom conf a few seconds later.</p>

<h2>The Better Way</h2>

<p>The OpsCode blog <a href="http://www.getchef.com/blog/2013/12/03/doing-wrapper-cookbooks-right/">Doing Wrapper Cookbooks Right</a> shows the right way, and really opened my eyes on the power of
Chef&rsquo;s two phase model (compile, then converge).</p>

<p>``` ruby
include_recipe &lsquo;nginx&rsquo;</p>

<h1>use our custom nginx.conf, rather than the one that ships in the nginx cookbook</h1>

<h1>this avoids the nginx and my-app cookbooks from fighting for control of</h1>

<h1>the same target file</h1>

<p>resources(&lsquo;template[nginx.conf]&rsquo;).cookbook &lsquo;my-app&rsquo;
```</p>
]]></content>
  </entry>
  
</feed>
